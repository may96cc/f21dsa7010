{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Python!\n",
    "\n",
    "In the practice, we learned how to conduct linear regression in the context of machine learning with `R`. You may have guessed it, but `sklearn` has a built in library for running linear regression models as well, however, its handling of inputs is a little bit different (we'll get into this later). Let's continue with the same `mpg` dataset. \n",
    "\n",
    "### Read in the Data\n",
    "\n",
    "We can actually read in the mpg data from the `/dsa/data/all_datasets/` directory. We can do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model # necessary package for linear regression\n",
    "\n",
    "with open('../../../datasets/mpg.csv') as file:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.drop('Unnamed: 0', 1) # remove id column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Sets\n",
    "\n",
    "In the previous module, we covered the topic of training and testing sets. Remember, we want to avoid overfitting our data, so we need to actually train the data on a subset of the entire data frame and then test it with a smaller subset. For this practice, we will split `df` into 70% training and use the other 30% as testing data. We'll go ahead and do that now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=7/10, random_state = 1)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define our inputs (the predictors) and the target (outcome). We will continue down the path of the `R` lab and use the `displ` and `class` variables as our inputs and the `hwy` as our target.  Remember back to module 6 where we had to convert these variables to `numpy` arrays. \n",
    "\n",
    "\n",
    "**Activity 1**: *Create a numpy array for the input variables `train[['displ, 'class']]` and call this object `train_X`. The create a numpy array for the target variable `train['hwy']` and call this `train_y`. Then do the same thing for the `test` data frame, but be sure to call the new objects `test_X` and `test_y`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Activity 1 goes here\n",
    "# *****************************\n",
    "\n",
    "train_X = np.asarray(train[['displ', 'class']])\n",
    "train_y = np.asarray(train.hwy)\n",
    "\n",
    "test_X = np.asarray(test[['displ', 'class']])\n",
    "test_y = np.asarray(test.hwy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Linear Regression Model\n",
    "\n",
    "Now that we have our inputs and targets defined for both the training and testing sets, the next step is to create the model. First we will create the linear regression object by calling the `LinearRegression()` method from the `linear_model` library. We will call this object `regr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `.fit()` method to train our model on the training variables...or can we? What happens when we run the following line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uhoh! Look at that value error. The `LinearRegression()` method implementation in `sklearn` needs floated inputs, and the `class` column is one full of `strings`.  In `R`, these can be handled appropriately, but in Python, you have to turn these values into dummy variables. In other words, we will create a column for each value in the `class`, and if that observation at that point is of that class, then it will be marked as 1, otherwise it will take the value 0. Take the following table for example.\n",
    "\n",
    "Observation | Color\n",
    "------------|------\n",
    "1           | 'Red'\n",
    "2           | 'Green'\n",
    "3           | 'Red'\n",
    "4           | 'Blue'\n",
    "\n",
    "Once we create dummy variables out of the `Color` column, the data will be in the following format...\n",
    "\n",
    "Observation | Red | Green | Blue\n",
    "------------|-----|-------|-----\n",
    "1 | 1.0| 0.0|0.0\n",
    "2 | 0.0| 1.0|0.0\n",
    "3 | 1.0| 0.0|0.0\n",
    "4 | 0.0| 0.0|1.0\n",
    "\n",
    "We would then use these three values as part of our input. The is exactly what we need to do with our `df` before we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables\n",
    "\n",
    "Fortunately, `pandas` provides us with a pretty convenient method for transforming a variable into some dummy variables. See what this looks like when we do this on the original `df` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to turn this into a separate data frame object and join it to our original data frame `df`.\n",
    "\n",
    "**Activity 2**: *Create an object of dummy variables from the `df['class']` variable. Call this new data frame object, `class_dummies`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Activity 2 goes here\n",
    "# *****************************\n",
    "\n",
    "class_dummies = pd.get_dummies(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the joining of the original `df` object to the newly created `class_dummies`. Since each observation of the `df` data frame lines up with each observation of the `class_dummies` data frame, we can use the following method to join the two frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, class_dummies], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything was created correct, we should see our original `df` with some extra columns (one from every category that was in the `class` column). What this method does is concatenate data frame objects on axis 1, or the column axis (remember, 0 is the row axis).\n",
    "\n",
    "Uhoh, but this is going to interfere with our old training and testing sets, so we are going to have to redefine those before we can make any progress.\n",
    "\n",
    "**Activity 3** : *Create a new testing and training set from the new data frame **`df2`**. Use the same parameters to define these two sets as we did for the original training and testing sets above. Call these objects `train` and `test` respectively.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Activity 3 goes here\n",
    "# *****************************\n",
    "\n",
    "\n",
    "train = df2.sample(frac=7/10, random_state = 1)\n",
    "test = df2.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh yes, and since we just created new training and testing sets, we have to define the inputs and targets for each set again. Below we will define the new input and target variables for the training set. Remember, the new inputs will include all of the dummy variables that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.asarray(train[['displ', '2seater', 'compact', 'midsize', 'minivan', 'pickup','subcompact','suv']])\n",
    "train_y = np.asarray(train.hwy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we need to do the same thing, except from the testing set.\n",
    "\n",
    "**Activity 4** : *Create the testing inputs and testing target from the the `test` data frame. Call these new objects `test_X` and `test_y` respectively.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Activity 4 goes here\n",
    "# *****************************\n",
    "\n",
    "\n",
    "test_X = np.asarray(test[['displ', '2seater', 'compact', 'midsize', 'minivan', 'pickup','subcompact','suv']])\n",
    "test_y = np.asarray(test.hwy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and train our data on the `regr` model object that we created above. Will it work this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it will! Now our `regr` model is trained from our training set. Let's see what the results look like. First, we can see the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the predictor variables' coefficients. Remember, these influence the intercept for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can zip that up to see the name of the variable by the coefficient. It is important to note the difference between `R` and `Python` in this case. In this case, to find the intercept of a particular class, you would take the intercept + the displacement coefficient + the class coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zip(['displ', '2seater', 'compact', 'midsize', 'minivan', 'pickup','subcompact','suv'],regr.coef_)\n",
    "list(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Model\n",
    "\n",
    "We can then assess the model by looking at the R-Squared value of the training set. In `Python` they call this method `.score` and we call it on the `regr` object and pass the inputs and output as arguments. Take a look below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R-Squared: {}'.format(regr.score(train_X, train_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to see how well our model predicts our testing set, and doing that is simple. Instead of passing the train inputs and target as arguments, pass the test.\n",
    "\n",
    "**Activity 5** : *Assess the performance of our `regr` by finding the `R-Squared` of our model on the testing set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Activity 5 goes here\n",
    "# *****************************\n",
    "\n",
    "print('R-Squared: {}'.format(regr.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! Not too shabby! \n",
    "\n",
    "And finally, if we wanted to predict some output with our model using our testing set inputs, or any new inputs, we can do so by calling the `predict()` method on the `regr` object and pass our input array as an argument. Take a look at how we do that on the `test_X` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remember what these points represent. They are the predicted highway mpg given that we know the displacement and class beforehand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
