{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice SQL\n",
    "\n",
    "Okay, our `SQL` feet are wet. \n",
    "We have seen how to load databases and how to query databases so let's step a little further into the `SQL` pool and query a larger database. \n",
    "In the previous notebooks, we were using a `SQLite` engine but `SQLite` is...well...lite. Instead, in this practice we are going to work with a `PostgreSQL` database, which is one of the most advanced open source `SQL` databases available. \n",
    "Before we begin, let's talk about the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Twitter Data\n",
    "\n",
    "We'll be working with \"some\" Twitter data in this practice. \n",
    "\"Some\" is in quotes only because we are working with over 250 million rows (250 with 6 ZEROS) and that is only \"some\" of what is being collected. \n",
    "This database has been collecting from 50 different US cities since from Jan 2017 until mid May 2017 for this particular copy of the database. \n",
    "\n",
    "--- \n",
    "\n",
    "Given the volume of data, this database server is a good introduction to some other database concepts we have yet to touch on. \n",
    "Again, `pandas` has some pretty neat tools for interacting with databases of all flavors. All we have to do is establish the connection and we can start making requests of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='pgsql.dsa.lan' password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "except:\n",
    "    print(\"Something went wrong...probably the wrong permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`psycopg2` is a package that allows `Python` to connect to a `Postgres` database.\n",
    "\n",
    "We didn't state this explicitly, but databases allow us to query other aspects of it other than tables. \n",
    "We can do something like write a query to get the table names in the database. \n",
    "Let's do that now so we can get an idea of what types of tables we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"SELECT table_name \n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'twitter'\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are working with a `tweet`, `hashtag`, `mention`, `url`, and `job` table, but that doesn't tell us a whole lot about the contents of any given table. \n",
    "At most, we can infer from the table names what type of data might be in them. \n",
    "But it would be better to know the attributes and perhaps what kind of data type they are. \n",
    "\n",
    "Again, we will be referencing the database's `information_schema` in order to pull this information out. \n",
    "Study the following query and compare it with the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"                              \n",
    "SELECT column_name, data_type, is_nullable\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'hashtag';\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know a bit about the contents of the of the `hashtag` table, which is good because we will be using it quite a bit in this practice. \n",
    "\n",
    "**Take a moment and contemplate the `CREATE TABLE` command that was used to create this table.**\n",
    "\n",
    "Moving on, we can explore what type of attributes are in the `tweet` data?\n",
    "\n",
    "**Activity 1:** Write a query to look at the column_names, data_types and character_maximum_lengths of the tweet table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Activity 1 goes here\n",
    "# --------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2:** How might you get **all** of the column characteristics (ie. `column_name`, `data_type`, etc.) for a single table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Activity 2 goes here\n",
    "# --------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's enough surface level exploring for now. \n",
    "Let's get our hands dirty a bit. \n",
    "To do that, we have to dig ;) into the data. \n",
    "\n",
    "Oh! but before we dig in we need to cover the idea of `LIMIT`. \n",
    "There are several reasons to put a `limit` on the number of rows returned in a query. \n",
    "For example, if we just want to get an idea of what our data looks like, we might specify a `LIMIT` of `5`. \n",
    "This is similar to running `head(dataframe_name)` in `R` or `dataframe_name.head()` in `Python`. \n",
    "But the reason we are using it is more for performance reasons. \n",
    "Remember, this is a fairly large database, and not specifying a limit and trying to pull millions of rows of data into Pandas could slow the operation down to a pace that is beyond the limit of your patience. \n",
    "\n",
    "So let's introduce `LIMIT` right now.\n",
    "\n",
    "```SQL\n",
    "SELECT <column_names>\n",
    "FROM <table_name>\n",
    "LIMIT <numeber_of_rows>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT * \n",
    "FROM twitter.hashtag\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Queries\n",
    "\n",
    "So **LIMIT**s employed for performance sake make for the appropriate time to cover nested queries. \n",
    "Nested queries are a good way to extract further information after performing some operation. \n",
    "Take the example below. \n",
    "We are trying to return a table that displays the unique hashtags in one column and how many times they occur in another. \n",
    "But remember, this database is large and we don't want to perform this over the entire table, \n",
    "so instead, we are going to perform this query over another query nested inside of it where we limit the number of rows to 1000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can break this query apart from the inner part first to the outer part.\n",
    "\n",
    "```SQL\n",
    "SELECT text\n",
    "FROM twitter.hashtag\n",
    "LIMIT 1000\n",
    "```\n",
    "\n",
    "We know what this query is going to return. \n",
    "It's going to return a table of only the `text` column form the `hashtag` table, \n",
    "but only the first 1000 rows. \n",
    "We will nest this table inside of another query so that it is only performing an aggregation off of a subset (1000 rows) of the data:\n",
    "\n",
    "```SQL\n",
    "SELECT DISTINCT text, COUNT(*)\n",
    "FROM( ...\n",
    "...) AS t1\n",
    "GROUP BY text\n",
    "```\n",
    "\n",
    "In this outer statement, we are wanting to know the unique terms as well as their counts for that 1000 rows we pull. \n",
    "The `AS t1` just names the nested query. \n",
    "Now we can take a look at what this actually returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT DISTINCT text, COUNT(*)\n",
    "FROM(\n",
    "    SELECT text\n",
    "    FROM twitter.hashtag\n",
    "    LIMIT 1000) AS t1\n",
    "GROUP BY text\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the column names of the returned data frame: `text` and `count`.  \n",
    "Right now there is no order and that can get a little annoying...\n",
    "\n",
    "\n",
    "**Activity 3:** Order the query above by `count`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Activity 3 goes here\n",
    "# --------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we want to know the most popular hashtags by `count`.\n",
    "\n",
    "**Activity 4:** Order the same query above from greatest to fewest count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Activity 4 goes here\n",
    "# ----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many databases also give the user the ability to perform operations on the columns within the query. \n",
    "These operations are very helpful in removing data carpentry steps from later on in our analysis. \n",
    "\n",
    "You may have noticed that some hashtags are actually repeated twice (or thrice or more) despite using `DISTINCT` on the `text` column. \n",
    "Can you identify why this is? \n",
    "Well, it is because `DISTINCT` is case sensitive and some hashtags are capitalized while others aren't. \n",
    "Fortunately, there is an operation that we can perform on the `text` column to transform these values all to one case on the fly.\n",
    "\n",
    "Take a look at the `LOWER()` operation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT LOWER(text) \n",
    "FROM twitter.hashtag\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 5:** Now, similar to the queries above, count the number of distinct hashtag `text`s but this time transform `text` to lower. Remember to put a `LIMIT` of 1000 in the nested query. Be sure to put the count in descending order.\n",
    "\n",
    "*HINT*: `LOWER()` should go in the nested portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Activity 5 goes here\n",
    "# --------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is so much more than just the `COUNT` of rows. \n",
    "You can also find the `AVERAGE` (arithmetic mean) of a numeric column. \n",
    "Keep in mind that the query below is `GROUP`ed `BY` `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT DISTINCT text, AVG(index_start)\n",
    "FROM(\n",
    "    SELECT lower(text) AS text, index_start\n",
    "    FROM twitter.hashtag\n",
    "    LIMIT 1000) AS t1\n",
    "GROUP BY text\n",
    "ORDER BY avg DESC\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to return to the world of `Joins` now. \n",
    "There is one thing we should add about `JOIN`s that we didn't have the opportunity to discuss in the lab. \n",
    "It is possible to perform a full outer join without using the `JOIN` statement. \n",
    "All you have to do is specify is what columns to match from the two (or more) tables in the `WHERE` clause. \n",
    "\n",
    "Take the example below. \n",
    "We are wanting to return all rows from both tables where the tweet_id matches in both the `hashtag` and `tweet` tables. \n",
    "Keep in mind, the `tweet` table has the column named `tweet_id_str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT t.tweet_id_str, t.text, h.text\n",
    "FROM twitter.tweet t, twitter.hashtag h\n",
    "WHERE t.tweet_id_str = h.tweet_id\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(statement,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
