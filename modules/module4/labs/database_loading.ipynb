{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "In this lab, we are going to focus on loading our data about baseball players into a database. \n",
    "Why use a database instead of files? \n",
    "Conceptually, we do this when we want to enforce rules on the structure of the data so that issues of cleanliness, \n",
    "inconsistency and missing data are identified prior to our attempts to do analysis. \n",
    "\n",
    "Database management systems provide well defined structure for data. \n",
    "They also have the advantage of giving us standard mechanisms for extracting data: \n",
    "\"Structured Query Language\", or \"SQL. \n",
    "If  you have not used SQL before, it will require a little adjustment. \n",
    "Once you are familiar with it, however, you will find SQL intuitive and portable.\n",
    "\n",
    "As you learned in the previous modules, Data Carpentry is often required to transform your messy data into a usable structure. \n",
    "Using a database allows you to store your transformed and cleaned data into a reusable, structured, and semantically labelled format.\n",
    "\n",
    "You can then access this data in the future using structured query language (SQL). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Procedure\n",
    "\n",
    "1. Inspect data, develop semantically structured data storage (i.e., database schema)\n",
    "2. Develop data transformations, cleaning, and re-organizations\n",
    "3. Push data into the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Inspect\n",
    "\n",
    "For this lab, we are going to use relatively clean data that is in nice comma separated values (CSV) format.\n",
    "Typically, the data requires data carpentry activities, but for the sake of a more simple collection of samples and discussion we are going to start with data that is already clean.\n",
    "\n",
    "To work with our data files we are going to use Pandas and Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "players = pd.read_csv('/dsa/data/all_datasets/baseball-databank/data/Master.csv')\n",
    "teams = pd.read_csv('/dsa/data/all_datasets/baseball-databank/data/Teams.csv')\n",
    "batting = pd.read_csv('/dsa/data/all_datasets/baseball-databank/data/Batting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we have loaded our three files into the variables: *players*, *teams*, and *batting*.\n",
    "Each of these variables is a Pandas **`data frame`**.\n",
    "As you have often done before, we can preview the data with the *`head()`* method called on the **`data frame`** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "As we can see, the CSV files are tabular data files. \n",
    "Note, in each case the tables cannot fit within the display and the *ellipsis* (...) is used to denote columns that are removed from the display.\n",
    "Do you recall how to view the columns of a dataframe?\n",
    "Like all things `python`, there are a few ways to do this.\n",
    "We will just use the list function to inspect the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to see all the columns of the dataframe this way\n",
    "\n",
    "Now lets do it for the other two data frames, teams and batting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"teams data frame : \\n {} \\n\".format(list(teams)))\n",
    "\n",
    "print(\"teams data frame : \\n {}\".format(list(batting)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We know the columns... now what?\n",
    "\n",
    "## Database Design\n",
    "\n",
    "Now that we know the columns, we need to contemplate how we will use a database to structure the data.\n",
    "A relational database is an organized set of __tables__ (aka *Relations*).\n",
    "\n",
    "__tables__ are a structured set of columns with semantic meaning, a particular data type, and constraints on validity.\n",
    "Not everyone may have the domain knowledge for baseball and the column labels. if you need some assistance please ask in mutual aid. \n",
    "For example, the *batting* column *RBI* we can expect to be *Runs Batted In*. \n",
    "\n",
    "#### SQL : Create Table\n",
    "```SQL\n",
    "CREATE TABLE table_name (\n",
    "  col_a_name col_a_datatype, \n",
    "  col_b_name col_b_datatype, \n",
    "  col_c_name col_c_datatype, \n",
    "  ...\n",
    "  PRIMARY KEY(list_of_columns)\n",
    ");\n",
    "```\n",
    "**REFERENCE LINK** [SQLite Create Table](https://www.sqlite.org/lang_createtable.html)\n",
    "\n",
    "### Column Data Types\n",
    "\n",
    "Databases support very rigid data typing, however SQLite permits looser *type affinity* based on storage classes.\n",
    "From the SQLite documentation: \n",
    "```\n",
    "Each column in an SQLite 3 database is assigned one of the following type affinities:\n",
    "    TEXT\n",
    "    NUMERIC\n",
    "    INTEGER\n",
    "    REAL\n",
    "    BLOB\n",
    "```\n",
    "\n",
    "For this activity, we will limit our storage columns to one of:\n",
    " 1. **TEXT** - Character strings\n",
    " 2. **INTEGER** - whole numbers, no decimal places\n",
    " 3. **REAL** - floating point numbers with decimal places\n",
    "\n",
    "\n",
    "**REFERENCE LINK** [SQLite Column Data Types](https://www.sqlite.org/datatype3.html)\n",
    "\n",
    "So, how can we examine in a programmatic way the data types as interpreted by Pandas?  \n",
    "Recall that a dataframe provides column access via __dataframe__['*column_name*'], and the column is an object that holds a list of values and the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype is the Data Type of the column that is referenced by name in the square brackets\n",
    "players['birthYear'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that birthYear is a floating point number, which above we refer to as a **REAL**\n",
    "\n",
    "Since we have `python` at our fingertips... lets programmatically inspect the columns and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember above, the list command did an inspection and \n",
    "# got a list of column names in the data frame!\n",
    "for columnName in list(players):\n",
    "    print(\"Column {} is a {}\".format(columnName, players[columnName].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should look similar to:\n",
    "```\n",
    "Column playerID is a object\n",
    "Column birthYear is a float64\n",
    "...\n",
    "Column bbrefID is a object\n",
    "```\n",
    "\n",
    "The **object** datatype we will interpret as **TEXT** for the database.\n",
    "Scroll back up to when we previewed the data files, does this seem reasonable?  \n",
    "Let us check, just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players['playerID'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems OK!\n",
    "You should typically check every column that you are going to load into the database.\n",
    "\n",
    "Once you are ready to create a table, we can write the create table statement:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE players (\n",
    "  playerID TEXT,\n",
    "  birthYear REAL,\n",
    "  ...\n",
    ");\n",
    "```\n",
    "\n",
    "Can we automate this for a generic CSV to SQL Table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "This segment of code shows the use of Python to automate the generation of a SQL Create Table statement from a Pandas dataframe.\n",
    "\n",
    "__Note:__ the special escape characters for *newline* (''\\n'') and *tab* (''\\t'') are used to generate visually pleasing SQL, they are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the create table statement\n",
    "createTableStmt = \"CREATE TABLE players (\\n\"\n",
    "\n",
    "# Build a translate from Panda to SQL type\n",
    "dtype2SQL = {'object' : 'TEXT', 'float64' : 'REAL', 'int64' : \"INTEGER\"}\n",
    "# Did you notice the int64 ?  That came from the teams and batting dataframes\n",
    "\n",
    "\n",
    "columnList = list(players)\n",
    "\n",
    "for columnName in columnList:\n",
    "    pandaType = str(players[columnName].dtype) # Note, we need to force the conversion of the type name to a string\n",
    "    sqlDataTypeStr = dtype2SQL[pandaType]      # Then we look up the SQL type Desired\n",
    "    #\n",
    "    #  Construct a Column Spec \n",
    "    #  col_name col_dtype , \n",
    "    createTableStmt += \"\\t{} {},\\n\".format(columnName, sqlDataTypeStr)\n",
    "    #\n",
    "    # NOTE:  the string1 += string2 appends string2 to the end of string 1, e.g., \"ABC\"+=\"XYZ\" results in \"ABCXYZ\"\n",
    "    #\n",
    "    \n",
    "    \n",
    "# Note, the last column has a trailing comma, so we can now add a Primary Key specification\n",
    "# If this is not suitable for the data file you have, you will need to make adjustments \n",
    "# such as removing the last comma before closing off the table.\n",
    "createTableStmt += \"\\tPRIMARY KEY({})\\n\".format(columnList[0])\n",
    "\n",
    "\n",
    "# Close off the Create Table Statement\n",
    "createTableStmt += \");\"\n",
    "\n",
    "print(len(createTableStmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes...this looks like a lot of code but it is actually making our lives a lot easier. Instead of having to write an entire statement ourselves, we can harness `python` to write our statement for us. We can break this down:\n",
    "\n",
    "The first line introduces the `createTableStmt` variable. You will notice throughout this code that we update this variable. It starts with a string that begins our `SQL` table construction. \n",
    "\n",
    "The next thing that we need to do is add the column names to the table and what type of data belongs in each column. To do this, we need to creating a mapping between analogous data types of `pandas` and `SQLite`. To do so, we create a dictionary, `dtype2SQL`, which uses the `panda`'s dtype as a key and the `SQLite` data type as the value.\n",
    "\n",
    "Next, we create a variable called `columnList` so that we can iterate through the columns. The following `for` loop is responsible for creating the meat of the `createTableStmt`. This loop breaks down as follows:\n",
    "\n",
    "```python\n",
    "pandaType = str(players[columnName].dtype)\n",
    "```\n",
    "This line just stores a string version of the `pandas` data type.\n",
    "\n",
    "```python\n",
    "sqlDataTypeStr = dtype2SQL[pandaType]\n",
    "```\n",
    "This then maps the `pandas` data type to the `SQLite` data type. We store this in a variable called `sqlDataTypeStr`.\n",
    "\n",
    "\n",
    "```python\n",
    "createTableStmt += \"\\t{} {},\\n\".format(columnName, sqlDataTypeStr)\n",
    "```\n",
    "And this is the line that adds to the original `createTableStmt`. The `+=` updates and saves to this variable. \n",
    "\n",
    "It then goes through the rest of the list of column names and keeps updating until the last column.\n",
    "\n",
    "\n",
    "After the `for` loop, the last thing to do is finish up the statement by updating the `createTableStmt`. Let's take a look at what this looks like by printing the statement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(createTableStmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `\\t` and `\\n` were not printed in this statement but instead were rendered as the intended tab and newline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's modularize this**\n",
    "\n",
    "Instead of writing out the whole block of code for every single table that we want to add into our database, we can create a function that takes only a couple arguments that will do all of the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2CreateTable(dataFrame, tableName = \"WHATS_MY_NAME\",useFirstColumnAsPK=True):\n",
    "    '''\n",
    "    This function inspects a Panda Dataframe and converts it to \n",
    "    a SQL Create Table Statement String\n",
    "    \n",
    "    Arguments:\n",
    "       dataFrame : a panda dataframe with column headers\n",
    "       tableName : a valid SQL table name\n",
    "       useFirstColumnAsPK : Use the first column as a primary key, default=True\n",
    "    \n",
    "    Returns : a Create Table tableName string\n",
    "    '''\n",
    "    createTableStmt = \"CREATE TABLE {} (\\n\".format(tableName)  # used the format to splice in the table name \n",
    "    dtype2SQL = {'object' : 'TEXT', 'float64' : 'REAL', 'int64' : \"INTEGER\"}\n",
    "    columnList = list(dataFrame)  # Replaced players from code with function variable\n",
    "    \n",
    "    for columnName in columnList:\n",
    "        # NOTE: Some of the columns start with a number, this is not valid column naming\n",
    "        # in most databases;  so the next four lines detect and fix\n",
    "        if (columnName[0].isdigit()):\n",
    "            sqlColumnName = \"n\"+columnName   # we will just prepend the letter 'n' (for number)\n",
    "        else:\n",
    "            sqlColumnName = columnName\n",
    "\n",
    "        pandaType = str(dataFrame[columnName].dtype) # Note, we need to force the conversion of the type name to a string\n",
    "        sqlDataTypeStr = dtype2SQL[pandaType]      # Then we look up the SQL type Desired\n",
    "        createTableStmt += \"\\t{} {},\\n\".format(sqlColumnName, sqlDataTypeStr)\n",
    "    # END OF FOR EACH COLUMN\n",
    "    \n",
    "    # Close off the Create Table Statement with the PK\n",
    "    if (useFirstColumnAsPK):\n",
    "        createTableStmt += \"\\tPRIMARY KEY({})\\n\".format(columnList[0])\n",
    "    else: # replace last comma with a space, note it's minus 2 because -1 is the newline\n",
    "                                          # This is the substring access \n",
    "                                          # see : https://docs.python.org/3/tutorial/introduction.html#strings\n",
    "        createTableStmt = createTableStmt[:len(createTableStmt) -2] + \"\\n\"\n",
    "    createTableStmt += \");\"\n",
    "    \n",
    "    return  createTableStmt\n",
    "# ------- END OF dataframe2CreateTable\n",
    "\n",
    "\n",
    "# Invoke\n",
    "help(dataframe2CreateTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting our DB creation together\n",
    "\n",
    "Now we can put the pieces together. First we are going to prepare our statements by using our newly developed `dataframe2CreateTable` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to write a SQLite DB\n",
    "import sqlite3\n",
    "\n",
    "playersCreateTableStmt = dataframe2CreateTable(dataFrame = players, tableName = 'players')\n",
    "teamsCreateTableStmt = dataframe2CreateTable(dataFrame = teams, tableName = 'teams', useFirstColumnAsPK=False)\n",
    "battingCreateTableStmt = dataframe2CreateTable(dataFrame = batting, tableName = 'batting', useFirstColumnAsPK=False)\n",
    "\n",
    "\n",
    "print(playersCreateTableStmt)\n",
    "print(teamsCreateTableStmt)\n",
    "print(battingCreateTableStmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** In reality, some of the column data types such as year and counting statistics should be INTEGER type.\n",
    "However, for this example we will just move forward.\n",
    "There are ways to manipulate the panda dataframe to move the data into a better aligned column data type.\n",
    "We will leave that as a thought exercise for now.\n",
    "\n",
    "__WARNING__ : \n",
    "Please note, that when we first connect to a database using SQLite and it does not exist, it gets created for us.  \n",
    "This *friendly* behavior can be REALLY CONFUSING on that day in the future when you have a file path wrong on a database you previously have populated and it looks empty to your code.  \n",
    "\n",
    "__REFERENCE__ : [Python SQLite3](https://docs.python.org/3/library/sqlite3.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Below is a pathname = ../baseball.db \n",
    "# The path is broken into elements around the '/' character (i.e., \"forward slash\" because it leans forward)\n",
    "# The first path element is the '..'  which is interpreted as the parent directory/folder. \n",
    "#        Look at the URL.  This notebook file is named: --- module4/labs/database_loading.ipynb\n",
    "#        This file is in a folder named labs, which is in a folder named module4.\n",
    "#        The above path name is therefore for module4/labs/../baseball.db\n",
    "#                   ... which is equivalent to module4/baseball.db\n",
    "#        We are putting the file there so it is accesible during exercises\n",
    "databaseFilename = '../baseball.db'\n",
    "\n",
    "# Just because we are creating this file here\n",
    "#  we will remove it incase you re-run the cell\n",
    "if os.path.exists(databaseFilename):\n",
    "    os.remove(databaseFilename)\n",
    "    \n",
    "# Open / Create the baseball.db database file.\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "\n",
    "# SQLite uses a cursor to track and manage and group operations.\n",
    "cursor = connection.cursor()\n",
    "# A cursor is a database execution context that provides isoation between \n",
    "#  the operations in the cursor and other operations that are happening\n",
    "#  simultaneously.\n",
    "# These operations can be undone by cancelling (i.e., ROLLBACK) the transaction before the cursor context \n",
    "#  is committed\n",
    "\n",
    "# Create tables\n",
    "cursor.execute(playersCreateTableStmt)\n",
    "cursor.execute(teamsCreateTableStmt)\n",
    "cursor.execute(battingCreateTableStmt)\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we have here? Well, the first statement is going to create a string with the desired database file name. The next two lines ...\n",
    "\n",
    "```python\n",
    "if os.path.exists(databaseFilename):\n",
    "    os.remove(databaseFilename)\n",
    "```\n",
    "\n",
    "... are going to check if that file exists on your operating system. If it does it will remove that database (because we are going to write a new one). \n",
    "\n",
    "Next we establish a connection to the database (take a look at the note above about if the database doesn't exist already).\n",
    "\n",
    "After the connection is established, we create a `cursor`, which allows us to execute statements independent of other happenings going on in the database. Once we create a `cursor` object, we can `execute` the statements that we created above. \n",
    "\n",
    "\n",
    "\n",
    "### Did this work?\n",
    "You can open the file using the command line ...\n",
    "\n",
    "... or we can use SQL and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Did this actually work?\n",
    "#  Open the DB file\n",
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "\n",
    "# Select the list of tables from the SQLite Engine Catalog for the database file\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Iterate through all the rows back, where the first column is the table name\n",
    "for table_name in tables:\n",
    "    print(table_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### FINALLY ... we get to load the data\n",
    "\n",
    "What this entails is iterating through the dataframe and inserting the values into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for row in players.itertuples(index=False):\n",
    "    cursor.execute('INSERT INTO players VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)',row)\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REFERENCE:__ [itertupples : Iterate Through Dataframe Rows, each row a tuple](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples)\n",
    "\n",
    "__How to see the data from the database prompt__\n",
    "![Select 5 players](../images/SQLite_baseball_select_5_players.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "batting.fillna(value=0) # Fill NaN values\n",
    "\n",
    "# Or stand on the shoulders including giants\n",
    "cursor.executemany('INSERT INTO batting VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)',\n",
    "                   batting.itertuples(index=False))\n",
    "\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__REFERENCE:__ Now that we did all this in a drawn out fashion, see [SQL Loading from Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html)  \n",
    "See Also: [SQLAlchemy](http://www.sqlalchemy.org/)\n",
    "\n",
    "\n",
    "__REMEMBER__ : This lab used clean CSV files that were mostly straight forward. Often, data carpentry activities require the efforts of the previous lab as well as the current lab.\n",
    "\n",
    "__ALSO REMEMBER__ : This is just a introduction for databases and we will come back to everything in the database course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
