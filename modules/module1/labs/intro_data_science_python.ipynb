{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science with `Python`\n",
    "\n",
    "<img src=\"../images/python_logo.png\" alt=\"python_logo\" style=\"width: 100px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going cover the very basics of data science in `Python`. Throughout this course, you will be introduced to many packages used by data scientists that make it easier to manipulate, visualize and model data. Today we will be working with one of the most popular Python data science packages, **`pandas`**. \n",
    "\n",
    "Before we begin doing some of the more complicated aspects of data science, it is important to get our feet wet with manipulating data. Now, it is impossible to cover all aspects of data manipulation because the scenarios are endless. It is the job of the data scientist to figure out the most creative and effective means by which to manipulate data. The purpose of this module is to get you comfortable with the tools and provide you with the grammar of data manipulation so that you can begin to string together your own data pipeline to meet your data science needs.\n",
    "\n",
    "\n",
    "**Python Reference Links:**\n",
    "\n",
    "  * [`Python` Standard Library](https://docs.python.org/3/library/)\n",
    "  * [`Python` Language Reference](https://docs.python.org/3/reference/)  \n",
    "  * [`pandas` Documentation](http://pandas.pydata.org/pandas-docs/stable/)\n",
    "  \n",
    "-----\n",
    " ## What we'll cover...\n",
    " \n",
    "- [Reading in Data](#reading)\n",
    "- [Soft Introduction to `pandas`](#pandas)\n",
    "- [Data Filtering](#filter)\n",
    "- [Data Sorting](#sort)\n",
    "- [To Come...](#future)\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "We will begin by reading in a dataset of baby name popularity in the U.S.\n",
    "\n",
    "We will reference this dataset by its column indexes so here is a table of them below.\n",
    "\n",
    "Index | Description\n",
    "------|------------\n",
    "`0`| Id\n",
    "`1`| Name\n",
    "`2`| Year\n",
    "`3`| Gender\n",
    "`4`| Count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reading'></a>\n",
    "\n",
    "## Reading In the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/dsa/data/all_datasets/baby-names/NationalNames1.csv', 'r')\n",
    "data = file.read()\n",
    "print(repr(data[0:101]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Above you were introduced to a function that you may be unfamiliar with, `repr` (short for \"*representation*\"). This returns the output in string format without escaping some of the special characters that we need to be aware of. Take for example the `\\n`, known as a newline character, which deliniates between rows in the original csv file. \n",
    "\n",
    "Having all of your data contained in a single string is less than desirable, particularly if you want do anything meaningful with it.  Let's change this so that instead of seeing a single string of data like you did above we see something more familiar to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dsa/data/all_datasets/baby-names/NationalNames1.csv', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "    data_lists = data.split(\"\\n\")\n",
    "\n",
    "    list_of_lists = []\n",
    "    for line in data_lists:\n",
    "        row = line.split(',')\n",
    "        list_of_lists.append(row)\n",
    "\n",
    "print(list_of_lists[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have, yet again, run into something you may think looks strange. The `with open(...)` statement above just executes everything in the indented block. In this case, it opens the file `NationalNames1.csv` and then reads it. Since this is read in a single string, we need to `split()` the string on the `\\n` character that we discussed above. This puts it in a format of different strings, or what may look like rows of data. However, we'll want to access different values within the rows, so in order to do that we need to split the rows by their delimiter. In this case, commas separate values, which is appropriate given the original file extension name `.csv`, which stands for \"comma separat*ed* values\". What this returns is a list of lists, which, believe it or not, makes the data easier to manipulate.\n",
    "\n",
    "But even this seems a bit complicated. If you are like me, simpler is generally preferred. \n",
    "\n",
    "Remember, packages in Python include different functions, which are made to aid you in your programming endeavors. Such a packages exists for reading in a `.csv` file, creatively named **`csv`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list = list(csv.reader(open('/dsa/data/all_datasets/baby-names/NationalNames1.csv'),  delimiter=','))\n",
    "print(data_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how easy that was and only one line of code! Okay, the line is jam-packed with functions inside functions, but it's nothing that we haven't seen before. The code block below breaks each part out into a format that we have seen before. \n",
    "\n",
    "```python\n",
    "    with open('/dsa/data/all_datasets/baby-names/NationalNames1.csv', 'r') as file:\n",
    "        data = csv.reader(file)\n",
    "\n",
    "        data_list = list(data)\n",
    "```\n",
    "\n",
    "The output of the function `csv.reader()` is non-subscriptable, meaning that we can't slice our data by indexes. Now, since each line is already a list, we just have to make the data a list of lists, which is as simple as calling the `list()` function on the `data` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Lists\n",
    "\n",
    "Why are we so obsessed with rendering the data in a list of lists? Why can't we just split the data by rows, like the code block below, and then call it a day? \n",
    "\n",
    "```python\n",
    "with open('/dsa/data/all_datasets/baby-names/NationalNames1.csv', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "    data_lists = data.split(\"\\n\")\n",
    "```\n",
    "\n",
    "This is tempting, but all it gives us are separate rows of data, which are not all that interesting if you can't access their values and compare them to other rows within the dataset. Think of this list of lists as a spreadsheet where you can access different cells individually. Some of you may know this as a matrix. It's not enough to just have access to individual rows; we also need access to columns or subsets of the data in order for analysis.  A list of lists isn't the only way to manipulate data (later on we will be discussing the more friendly and flexible concept of a data frame), but it is a good way to begin understanding how to interact with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable, `data_list` has a hair over 600,000 rows at the moment. Having access to this much data is nice, but let's scale it back a bit for quicker computations.  We're going to take a subset of the original data (only 300 rows) and remove the header, as this is really just metadata used to aid humans in keeping things orderly.\n",
    "\n",
    "From the subset, we are going to transform the column that contains the name `count`s into floats (we could also do integers if we wanted to) as they are currently strings, and you can't run mathematical operations on strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_list[1:301]\n",
    "\n",
    "count_floats = []         \n",
    "\n",
    "for row in subset:\n",
    "    count_flo = float(row[4])\n",
    "    count_floats.append(count_flo)\n",
    "\n",
    "count_floats[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the code above looks like in plain English, step by step: \n",
    "1. We created a subset of the data_list of only the first 300 rows. Remember `data_list[1:301]` is going to start at index `1` (*which is the second item*) and end at index `301`, not including index `301` itself.\n",
    "2. We created an empty list called, `count_floats` where we are going to store our converted `count` data.\n",
    "3. We performed a `for` loop which iterates through each row in the `subset` and: \n",
    "    1. converts the `4th` index in each row to a float. \n",
    "    2. appends that newly made float to `count_floats` list above.\n",
    "4. Return the first five items of the `count_floats` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to find all of the male names in this `subset` and `print` them out? How might we interact with the rows and columns of the data to perform this action? This would require us to refer to two different indexes within each row: 1) the `3rd`\\* index, which gives us the `sex` associated with the name, and 2) the `1st`\\*\\* index, which contains the `name` itself. We're going to use a conditional statement in order to achieve our goal.\n",
    "\n",
    "\\* *when we say \"3rd\" index, we don't mean third chronologically. Remember, `Python` indexes its lists starting with 0, so when we say 3rd, we are saying that the index value of the list is 3.*\n",
    "\n",
    "\\*\\* *when we say \"1st\" index, we mean it has the index value of 1, not to be confused with the \"0th\" index, or the chronologically first index of the list. See note above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in subset:\n",
    "    if row[3] == 'M':\n",
    "        print(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we are going to use a `for` loop to interate through our `subset` of data.  We are then going to use a conditional statement to check **`if`** the `3rd` index in the row is equal to `M`, meaning male. Remember, a condition will return either `True` of `False`. If that statement is `True` then it will `print` out the value of the `1st` index, which is the column containing the name; if it is `False` then it will just skip over it.\n",
    "\n",
    "\n",
    "**On your own:** *Think about how you might add these names to a list type variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On your own: add these names to a list of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas'></a>\n",
    "\n",
    "## Using `pandas`\n",
    "\n",
    "<img src=\"../images/pandas_logo.png\" alt=\"python_logo\" style=\"width: 600px;\"/>\n",
    "\n",
    "`pandas` is a popular data science package for `Python`. It includes different data structures and tools, which provide for flexible data manipulation and analysis. Throughout this course, we will be using what are known as data frames, a 2-dimensional table that supports different data types. This is one of the key structures that `pandas` provides, and one that will return in `R`.\n",
    "\n",
    "Here is how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/dsa/data/all_datasets/baby-names/NationalNames1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that simple! \n",
    "\n",
    "`.head()` is a pandas function that returns the first n rows for the object based on position. It is useful for quickly testing if your object has the right type of data in it. By default it returned 5. \n",
    "\n",
    "However to really start working with the data we will want to get rid of the old 'Id' column in the file. \n",
    "\n",
    "Let's see what this looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Id'] \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets put that all together. \n",
    "\n",
    "Keeping the load and the deletion of the column together is good practice as this way when you are rerunning code you will always load the data and then remove the column at the same time. If you have them separate you may try to run the deletion of the column code before reloading the data which would cause an error because the column was already deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/dsa/data/all_datasets/baby-names/NationalNames1.csv', 'r') as file:\n",
    "    df = pd.read_csv(file)\n",
    "del df['Id'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, you should notice that it is rendered in a much cleaner format than the list of lists above. It looks more familiar, like something more akin to a spreadsheet. Even if you were to execute this within your terminal application, it would be rendered in such a way that it keeps the data in rows and columns. \n",
    "\n",
    "As you can see, the top row is going to be a header row. Whereas we had to remove the header row in the list of lists in order to manipulate the data, this row serves as a reference to the columns in `pandas`. The unnamed column on the left is your index column. \n",
    "\n",
    "\n",
    "**On your own:** *What do you think `.tail()` returns?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On your own: See what .tail() returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='filter'></a>\n",
    "\n",
    "## Data Filtering\n",
    "\n",
    "`pandas` allows us to easily filter data. Imagine that you were only interested in tracking how many people each year named their child \"James\". All we have to do is filter the `Name` column by the string \"James\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Name']=='James'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a very simple line of code, which is one of the benefits of using `pandas`. We can break it down step by step. Let's start with the line `df['Name']=='James'`. This is going to return `True` or `False` given whether or not the condition is met. Running this line by itself would just return a boolean for each index.  For this reason, we wrap that in `df[...]`, which returns the subset of the dataframe, `df` where the index returns `True`, thus returning all rows that match the string, \"James\".  Once again, the final `.head()` piece is a `pandas` method that you can call on dataframes to return the first rows. You could pass a numerical argument to return the first X-number of rows. For example, if we put `df[df['Name']=='James'].head(10)`, the first 10 rows of this subset would be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Name'] == 'James') & (df['Count'] > 6000) & (df['Count'] < 10000)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` can also match on much more than strings. Take the above example, which builds on the \"James\" subset. What if we were interested in knowing which years had a greater than 400 *James*es named but less than 10,000? That's what we did above. `pandas` allows us to match on many conditions very easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sort'></a>\n",
    "\n",
    "## Data Sorting\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort the data frame by a column. This works on both numerical data types as well as strings. For example, sorting by `df['Name']` will sort the data frame alphabetically by the 'Name' column, while sorting by `df['Count']`  will sort by numerical value. Take a look at the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['Count'], ascending = True).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='future'></a>\n",
    "\n",
    "## And to Come...\n",
    "\n",
    "Data manipulation is just the beginning of our data science curriculum, but understanding it is key before we start to model or visualize our data.\n",
    "\n",
    "In a few modules from now, we will be working with some machine learning techniques and predicting target variables based on some input data. Below is a scatter plot depicting the relationship between brain and body size in a small subset of animals. The line in the graph is a regression line depicting the relationship between the two variables, brain and body size.\n",
    "\n",
    "Linear regression is just one of several machine learning algorithms that we will be exploring in the class. In the end, we will know how to select the right algorithm given the prediction problem, interpret the output, and refine the model for prediction optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/brain_body_python.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
